{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-05-04T12:54:52.943299Z",
     "start_time": "2024-05-04T12:54:52.819047Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "data = pd.read_csv('data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "outputs": [
    {
     "data": {
      "text/plain": "        Example  Complaint  Farewell  Feedback  Greet  Inquiry  Navigation  \\\n0            Hi      False     False     False   True    False       False   \n1         Hello      False     False     False   True    False       False   \n2     Hey there      False     False     False   True    False       False   \n3  Good morning      False     False     False   True    False       False   \n4         Howdy      False     False     False   True    False       False   \n\n   Request  \n0    False  \n1    False  \n2    False  \n3    False  \n4    False  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Example</th>\n      <th>Complaint</th>\n      <th>Farewell</th>\n      <th>Feedback</th>\n      <th>Greet</th>\n      <th>Inquiry</th>\n      <th>Navigation</th>\n      <th>Request</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Hi</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Hello</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Hey there</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Good morning</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Howdy</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot = pd.get_dummies(data['Intent'])\n",
    "data = data.drop('Intent', axis=1)\n",
    "data = data.join(one_hot)\n",
    "\n",
    "data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T12:54:52.946506Z",
     "start_time": "2024-05-04T12:54:52.855109Z"
    }
   },
   "id": "40bbafaa37fdcdac"
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "outputs": [
    {
     "data": {
      "text/plain": "((292, 8), (37, 8), (36, 8))"
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data, test_data = train_test_split(data, train_size=0.8, random_state=10)\n",
    "validation_data, test_data = train_test_split(test_data, train_size=0.5, random_state=10)\n",
    "\n",
    "train_data.shape, test_data.shape, validation_data.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T12:54:52.947700Z",
     "start_time": "2024-05-04T12:54:52.879107Z"
    }
   },
   "id": "b827badb4443cc45"
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "outputs": [
    {
     "data": {
      "text/plain": "                                 Example  Complaint  Farewell  Feedback  \\\n34              A warm welcome to class!      False     False     False   \n87                   Until we meet again      False      True     False   \n57                       Have a good one      False      True     False   \n152  How do I change my mailing address?      False     False     False   \n204            The product is defective.       True     False     False   \n\n     Greet  Inquiry  Navigation  Request  \n34    True    False       False    False  \n87   False    False       False    False  \n57   False    False       False    False  \n152  False     True       False    False  \n204  False    False       False    False  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Example</th>\n      <th>Complaint</th>\n      <th>Farewell</th>\n      <th>Feedback</th>\n      <th>Greet</th>\n      <th>Inquiry</th>\n      <th>Navigation</th>\n      <th>Request</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>34</th>\n      <td>A warm welcome to class!</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>87</th>\n      <td>Until we meet again</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>57</th>\n      <td>Have a good one</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>152</th>\n      <td>How do I change my mailing address?</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n    <tr>\n      <th>204</th>\n      <td>The product is defective.</td>\n      <td>True</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n      <td>False</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first 5 rows of the train_data\n",
    "train_data.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T12:54:52.962017Z",
     "start_time": "2024-05-04T12:54:52.889395Z"
    }
   },
   "id": "70645a7ec6073077"
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "outputs": [],
   "source": [
    "# turn everything to lowercase\n",
    "train_data['Example'] = train_data['Example'].str.lower()\n",
    "test_data['Example'] = test_data['Example'].str.lower()\n",
    "validation_data['Example'] = validation_data['Example'].str.lower()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T12:54:52.962123Z",
     "start_time": "2024-05-04T12:54:52.900549Z"
    }
   },
   "id": "4a22d030e0c9ef03"
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lakshithnishshanke/miniconda3/envs/labml/lib/python3.9/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": "[1037, 4010, 6160, 2000, 2465, 999]"
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "tokens = tokenizer.tokenize(train_data['Example'].values[0])\n",
    "\n",
    "tokenizer.convert_tokens_to_ids(tokens)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T12:54:53.882843Z",
     "start_time": "2024-05-04T12:54:52.915109Z"
    }
   },
   "id": "4f0e639e57be59bb"
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "all_letters = 'abcdefghijklmnopqrstuvwxyz\\'?! '\n",
    "n_letters = len(all_letters)\n",
    "\n",
    "def letterToIndex(letter):\n",
    "    return all_letters.find(letter)\n",
    "\n",
    "def letterToTensor(letter):\n",
    "    tensor = torch.zeros(1, n_letters, dtype=torch.float32)\n",
    "    tensor[0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "def lineToTensor(line):\n",
    "    tensor = torch.zeros(80, 1, n_letters)\n",
    "    for li, letter in enumerate(line):\n",
    "        tensor[li][0][letterToIndex(letter)] = 1\n",
    "    return tensor\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data):\n",
    "        sentences = data['Example'].values\n",
    "        \n",
    "        print(len(sentences))\n",
    "        \n",
    "        inputs = [lineToTensor(sentence) for sentence in sentences]\n",
    "        \n",
    "        self.inputs = torch.cat(inputs).reshape(len(inputs), inputs[0].shape[0], n_letters)\n",
    "            \n",
    "        print(self.inputs.shape)\n",
    "        \n",
    "        self.outputs = torch.tensor(data.drop('Example', axis=1).values, dtype=torch.float32)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return self.inputs[index], self.outputs[index]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.inputs)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T12:54:53.889241Z",
     "start_time": "2024-05-04T12:54:53.883931Z"
    }
   },
   "id": "76cad51bb306b181"
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292\n",
      "torch.Size([292, 80, 30])\n",
      "37\n",
      "torch.Size([37, 80, 30])\n",
      "36\n",
      "torch.Size([36, 80, 30])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = CustomDataset(train_data)\n",
    "test_dataset = CustomDataset(test_data)\n",
    "validation_dataset = CustomDataset(validation_data)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T12:54:53.972724Z",
     "start_time": "2024-05-04T12:54:53.892163Z"
    }
   },
   "id": "b0e08ae15575d14f"
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "outputs": [],
   "source": [
    "batch_size = 16"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T12:54:53.981140Z",
     "start_time": "2024-05-04T12:54:53.976265Z"
    }
   },
   "id": "27c5cceea37bc2b2"
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "outputs": [
    {
     "data": {
      "text/plain": "(19, 3, 3)"
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "validation_loader = DataLoader(validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "len(train_loader), len(test_loader), len(validation_loader)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T12:54:53.992723Z",
     "start_time": "2024-05-04T12:54:53.986469Z"
    }
   },
   "id": "47004910115e4967"
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "outputs": [
    {
     "data": {
      "text/plain": "[tensor([[[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]],\n \n         [[0., 0., 1.,  ..., 0., 0., 0.],\n          [1., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]],\n \n         [[1., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 1.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]],\n \n         ...,\n \n         [[0., 0., 1.,  ..., 0., 0., 0.],\n          [1., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]],\n \n         [[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]],\n \n         [[0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          ...,\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.],\n          [0., 0., 0.,  ..., 0., 0., 0.]]]),\n tensor([[0., 0., 0., 0., 0., 0., 1.],\n         [0., 0., 0., 0., 0., 0., 1.],\n         [0., 0., 0., 1., 0., 0., 0.],\n         [1., 0., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 1., 0., 0., 0.],\n         [0., 1., 0., 0., 0., 0., 0.],\n         [0., 1., 0., 0., 0., 0., 0.],\n         [0., 0., 1., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 0., 1.],\n         [0., 0., 0., 0., 0., 1., 0.],\n         [0., 0., 1., 0., 0., 0., 0.],\n         [0., 1., 0., 0., 0., 0., 0.],\n         [0., 0., 0., 0., 0., 1., 0.],\n         [0., 0., 0., 0., 0., 1., 0.],\n         [0., 0., 0., 0., 0., 1., 0.],\n         [0., 0., 0., 0., 0., 1., 0.]])]"
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first batch of the train_loader\n",
    "next(iter(train_loader))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T12:54:54.040128Z",
     "start_time": "2024-05-04T12:54:53.996848Z"
    }
   },
   "id": "77e20ee7842b57e3"
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.hidden_size = 64\n",
    "\n",
    "        self.i2h = nn.Linear(30, self.hidden_size)\n",
    "        self.h2h = nn.Linear(self.hidden_size, self.hidden_size)\n",
    "        self.h2o = nn.Linear(self.hidden_size, 7)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        hidden = F.tanh(self.i2h(input) + self.h2h(hidden))\n",
    "        output = self.h2o(hidden)\n",
    "        output = self.softmax(output)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(30, self.hidden_size)\n",
    "\n",
    "n_hidden = 64\n",
    "rnn = RNN()\n",
    "\n",
    "rnn = rnn.float()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T12:54:54.040447Z",
     "start_time": "2024-05-04T12:54:54.020572Z"
    }
   },
   "id": "9867f20200624531"
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "outputs": [],
   "source": [
    "# input = torch.tensor([1.0])\n",
    "# hidden = torch.zeros(1, 64)\n",
    "# \n",
    "# output, next_hidden = rnn(input, hidden)\n",
    "# output"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T12:54:54.040940Z",
     "start_time": "2024-05-04T12:54:54.032662Z"
    }
   },
   "id": "cff6a50feed4a481"
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "outputs": [],
   "source": [
    "criterion = nn.NLLLoss()\n",
    "learning_rate = 1e-4"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T12:54:54.040969Z",
     "start_time": "2024-05-04T12:54:54.034877Z"
    }
   },
   "id": "38c2147ec8d7a19f"
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Finishing last run (ID:0d818jwu) before initializing another..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "VBox(children=(Label(value='0.046 MB of 0.046 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2337a97a4e344f2fbe7b0d695a4813d8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<style>\n    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n    </style>\n<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>▃▁▁▁▁▁▁▁▁▁▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆▆████████████</td></tr><tr><td>Loss</td><td>▅▃▅▄▄█▄▁▅▄▅▃▄▄▄▄▅▃▆▃▂▂▅▂▅▅▃▅▄▃▅▂▃▄▅▂▃▁▂▅</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>0.24324</td></tr><tr><td>Loss</td><td>1.90028</td></tr></table><br/></div></div>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run <strong style=\"color:#cdcd00\">rebel-destroyer-9</strong> at: <a href='http://localhost:8080/lakshith/Intellihack_2/runs/0d818jwu' target=\"_blank\">http://localhost:8080/lakshith/Intellihack_2/runs/0d818jwu</a><br/> View job at <a href='http://localhost:8080/lakshith/Intellihack_2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjU=/version_details/v8' target=\"_blank\">http://localhost:8080/lakshith/Intellihack_2/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjU=/version_details/v8</a><br/>Synced 7 W&B file(s), 0 media file(s), 3 artifact file(s) and 0 other file(s)"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Find logs at: <code>./wandb/run-20240504_180401-0d818jwu/logs</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Successfully finished last run (ID:0d818jwu). Initializing new run:<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "wandb version 0.16.6 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Tracking run with wandb version 0.16.3"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Run data is saved locally in <code>/Users/lakshithnishshanke/Developer/Intellihack/Intellihack_Rizzmoid_2/wandb/run-20240504_182454-hgaml6em</code>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "Syncing run <strong><a href='http://localhost:8080/lakshith/Intellihack_2/runs/hgaml6em' target=\"_blank\">ancient-pilot-10</a></strong> to <a href='http://localhost:8080/lakshith/Intellihack_2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View project at <a href='http://localhost:8080/lakshith/Intellihack_2' target=\"_blank\">http://localhost:8080/lakshith/Intellihack_2</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": " View run at <a href='http://localhost:8080/lakshith/Intellihack_2/runs/hgaml6em' target=\"_blank\">http://localhost:8080/lakshith/Intellihack_2/runs/hgaml6em</a>"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='http://localhost:8080/lakshith/Intellihack_2/runs/hgaml6em?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>",
      "text/plain": "<wandb.sdk.wandb_run.Run at 0x312156370>"
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "configs = {\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"architecture\": \"RNN\",\n",
    "    \"dataset\": \"custom\",\n",
    "}\n",
    "\n",
    "wandb.init(\n",
    "    project=\"Intellihack_2\",\n",
    "    config=configs\n",
    ")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T12:55:01.748380Z",
     "start_time": "2024-05-04T12:54:54.036765Z"
    }
   },
   "id": "c9dbc27cb64b8a99"
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "outputs": [],
   "source": [
    "def train(category_tensor, line_tensor):\n",
    "    hidden = rnn.initHidden()\n",
    "    line_tensor = line_tensor.float()\n",
    "    \n",
    "    # print(torch.unsqueeze(line_tensor[:,0], 1).shape)\n",
    "\n",
    "    rnn.zero_grad()\n",
    "\n",
    "    for i in range(line_tensor.size(1)):\n",
    "        output, hidden = rnn(torch.unsqueeze(line_tensor[:,i], 1), hidden)\n",
    "    \n",
    "    print(output.shape, category_tensor.shape)\n",
    "    \n",
    "    # convert category tensor to indices\n",
    "    category_tensor = torch.argmax(category_tensor, dim=1)\n",
    "    \n",
    "    loss = criterion(output, category_tensor)\n",
    "    loss.backward()\n",
    "\n",
    "    # Add parameters' gradients to their values, multiplied by learning rate\n",
    "    for p in rnn.parameters():\n",
    "        p.data.add_(p.grad.data, alpha=-learning_rate)\n",
    "        \n",
    "    wandb.log({\n",
    "        \"Loss\": loss.item()\n",
    "    })\n",
    "\n",
    "    print(loss.item())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T12:55:49.180092Z",
     "start_time": "2024-05-04T12:55:49.160431Z"
    }
   },
   "id": "cbd72e273768eaec"
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "outputs": [],
   "source": [
    "def test_evaluate():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for i, (input, output_data) in enumerate(test_loader):\n",
    "            hidden = rnn.initHidden()\n",
    "            input = input.float()\n",
    "            \n",
    "            for i in range(input.size(1)):\n",
    "                output, hidden = rnn(torch.unsqueeze(input[:,i], 1), hidden)\n",
    "            \n",
    "            total += output.size(0)\n",
    "            correct += (torch.argmax(output_data, dim=1) == torch.argmax(output, dim=1)).sum().item()\n",
    "            \n",
    "        wandb.log({\n",
    "            \"Accuracy\": correct / total\n",
    "        })\n",
    "            \n",
    "    print('Accuracy of the network on the test examples: %d %%' % (100 * correct / total))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T12:55:50.270039Z",
     "start_time": "2024-05-04T12:55:50.260448Z"
    }
   },
   "id": "30d9ca58edd3400a"
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 30, 7]) torch.Size([16, 7])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected target size [16, 7], got [16]",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[210], line 5\u001B[0m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[1;32m      4\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m i, (\u001B[38;5;28minput\u001B[39m, output) \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(train_loader):\n\u001B[0;32m----> 5\u001B[0m         \u001B[43mtrain\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      6\u001B[0m     test_evaluate()\n",
      "Cell \u001B[0;32mIn[208], line 17\u001B[0m, in \u001B[0;36mtrain\u001B[0;34m(category_tensor, line_tensor)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# convert category tensor to indices\u001B[39;00m\n\u001B[1;32m     15\u001B[0m category_tensor \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39margmax(category_tensor, dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[0;32m---> 17\u001B[0m loss \u001B[38;5;241m=\u001B[39m \u001B[43mcriterion\u001B[49m\u001B[43m(\u001B[49m\u001B[43moutput\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcategory_tensor\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     18\u001B[0m loss\u001B[38;5;241m.\u001B[39mbackward()\n\u001B[1;32m     20\u001B[0m \u001B[38;5;66;03m# Add parameters' gradients to their values, multiplied by learning rate\u001B[39;00m\n",
      "File \u001B[0;32m~/miniconda3/envs/labml/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[0;34m(self, *args, **kwargs)\u001B[0m\n\u001B[1;32m   1496\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[1;32m   1497\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[1;32m   1498\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[1;32m   1499\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[1;32m   1500\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[0;32m-> 1501\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1502\u001B[0m \u001B[38;5;66;03m# Do not call functions when jit is used\u001B[39;00m\n\u001B[1;32m   1503\u001B[0m full_backward_hooks, non_full_backward_hooks \u001B[38;5;241m=\u001B[39m [], []\n",
      "File \u001B[0;32m~/miniconda3/envs/labml/lib/python3.9/site-packages/torch/nn/modules/loss.py:216\u001B[0m, in \u001B[0;36mNLLLoss.forward\u001B[0;34m(self, input, target)\u001B[0m\n\u001B[1;32m    215\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m: Tensor, target: Tensor) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Tensor:\n\u001B[0;32m--> 216\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnll_loss\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mignore_index\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreduction\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/envs/labml/lib/python3.9/site-packages/torch/nn/functional.py:2704\u001B[0m, in \u001B[0;36mnll_loss\u001B[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001B[0m\n\u001B[1;32m   2702\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m size_average \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m reduce \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   2703\u001B[0m     reduction \u001B[38;5;241m=\u001B[39m _Reduction\u001B[38;5;241m.\u001B[39mlegacy_get_string(size_average, reduce)\n\u001B[0;32m-> 2704\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_C\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_nn\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mnll_loss_nd\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mweight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m_Reduction\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_enum\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreduction\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mignore_index\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: Expected target size [16, 7], got [16]"
     ]
    }
   ],
   "source": [
    "# iterate data loader and train\n",
    "epochs = 5000\n",
    "for epoch in range(epochs):\n",
    "    for i, (input, output) in enumerate(train_loader):\n",
    "        train(output, input)\n",
    "    test_evaluate()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-04T12:55:51.421363Z",
     "start_time": "2024-05-04T12:55:51.288030Z"
    }
   },
   "id": "2c9215aca4f7608d"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-05-04T12:55:02.256894Z"
    }
   },
   "id": "6a40ca5f9990d524"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
